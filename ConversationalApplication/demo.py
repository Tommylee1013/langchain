## library import

import os
from dotenv import load_dotenv
import streamlit as st
import openai
from langchain.memory import ConversationBufferMemory
from langchain_community.llms import OpenAI
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.document_loaders import PyPDFLoader
from langchain.chains import ConversationalRetrievalChain
from langchain.agents.agent_toolkits import create_retriever_tool
from langchain.agents.agent_toolkits import create_conversational_retrieval_agent
from langchain_community.utilities import SerpAPIWrapper
from langchain_community.callbacks.streamlit import StreamlitCallbackHandler
from langchain.tools import BaseTool, Tool, tool
from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema import ChatMessage
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_core.prompts import PromptTemplate
from langchain.chains import LLMChain

## config API
with open('../config/api.key') as file :
    lines = file.readlines()
    api_key = lines[0].strip()
    serp_api_key = lines[1].strip()
    langsmith_api_key = lines[2].strip()

openai.api_key = api_key
os.environ['SERPAPI_API_KEY'] = serp_api_key

st.set_page_config(page_title = 'Conversational Application', page_icon = 'ğŸŒ')

st.header('Conversational Application')
st.write('ì•ˆë…•í•˜ì„¸ìš”. ê¸ˆìœµì— ëŒ€í•œ ì¡°ì–¸ì„ í•´ì£¼ëŠ” AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.')
st.write('ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?')

search = SerpAPIWrapper()

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 1500,
    chunk_overlap = 200
)

raw_documents = PyPDFLoader('../data/portfolio_management_giude.pdf').load()
documents = text_splitter.split_documents(raw_documents)
db = FAISS.from_documents(documents, OpenAIEmbeddings())

memory = ConversationBufferMemory(
    return_messages = True,
    memory_key = 'chat_history',
    output_key = 'output'
)

llm = ChatOpenAI(model = 'gpt-4o-mini')

tools = [
    Tool.from_function(
        func = search.run,
        name = "Search",
        description = "í˜„ì¬ ì¼ì–´ë‚˜ê³  ìˆëŠ” ì¼ì— ê´€í•œ ì§ˆë¬¸ì— ë‹µí•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤."
    ),
    create_retriever_tool(
        db.as_retriever(),
        "portfolio_management",
        "í¬íŠ¸í´ë¦¬ì˜¤ ìš´ìš©ì— ê´€í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•´ì„œ ë°˜í™˜í•©ë‹ˆë‹¤."
    )
]

agent = create_conversational_retrieval_agent(llm, tools, memory_key='chat_history', verbose=True)

user_query = st.text_input(
    "**ì–´ë–¤ ì¢…ëª©ì— íˆ¬ìë¥¼ ì›í•˜ì‹œë‚˜ìš”?**",
    placeholder="ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”!"
)

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}]
if "memory" not in st.session_state:
    st.session_state['memory'] = memory

# ì „ì²´ ëŒ€í™” í‘œì‹œë¥¼ ìœ„í•œ ë£¨í”„
for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).write(msg["content"])

# ì‚¬ìš©ì ì¿¼ë¦¬ê°€ ì£¼ì–´ì¡Œì„ ë–„ ì‘ë‹µí•˜ë„ë¡ AI assistant êµ¬ì¶•í•˜ê¸°
def display_msg(msg, author):
    st.session_state.messages.append({"role": author, "content": msg})
    st.chat_message(author).write(msg)

if user_query:
    display_msg(user_query, 'user')
    with st.chat_message("assistant"):
        st_cb = StreamlitCallbackHandler(st.container())
        response = agent(user_query, callbacks=[st_cb])
        st.session_state.messages.append({"role": "assistant", "content": response})
        st.write(response)

if st.sidebar.button("ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”"):
    st.session_state.messages = []